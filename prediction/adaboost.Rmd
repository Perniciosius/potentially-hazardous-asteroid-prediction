```{r}
library(adabag)
library(caTools)
library(Metrics)
```

#data pre processing
```{r}
featureSelection <- function(data) {
  # Highly correlated features
  correlationMatrix <- cor(data[, names(data) != "pha"])
  
  # Index of highly correlation features
  hightlyCorrelated <- findCorrelation(correlationMatrix,
                                       cutoff = 0.9, names = TRUE)
  
  # Remove highly correlated features
  data <- data[, !names(data) %in% hightlyCorrelated]
  return(data)
}


dataCleaning <- function(data) {
  # Remove unnecessary field
  data <- data[, !names(data)
               %in% c("prefix", "id", "spkid", "full_name", "pdes",
                      "name", "orbit_id", "equinox", "neo", "class")]
  
  # Remove NA data
  data <- na.omit(data)
  
  # Categorical data
  data <- transform(
    data,
    pha = as.factor(pha)
  )
  
  return(data)
}
```

```{r}
data=read.csv("dataset.csv")
head(data)
data$pha=as.factor(data$pha)
```

```{r}
data1=dataCleaning(data)
data2=featureSelection(data1)
head(data2)
```

```{r}
sample = sample.split(data2$pha, SplitRatio = 0.75)
train = subset(data2, sample == TRUE)
test = subset(data2, sample == FALSE)

```

```{r}
model = boosting(pha~., data=train)
```

```{r}
pred=predict(model,test)
```

```{r}
error=as.numeric(format(pred$error,scientific = FALSE))
accuracy=1-error
accuracy
```
```{r}
pred$confusion
```

